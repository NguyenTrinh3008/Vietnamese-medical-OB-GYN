#!/usr/bin/env python3
"""
Critic Agent - Kiá»ƒm tra faithfulness vÃ  medical safety
Migrate tá»« critic_node() trong agentic_rag.py
"""

import sys
sys.path.append('..')

from async_agents.base import BaseAgent, AgentState
from typing import List, Dict, Any
import json


def llm_json(system: str, user: str, openai_client, model: str, max_tokens=1000) -> Dict[str, Any]:
    """Call OpenAI API vá»›i JSON response format"""
    try:
        resp = openai_client.chat.completions.create(
            model=model,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
            response_format={"type": "json_object"},
            temperature=0.0,
            max_tokens=max_tokens,
        )
        return json.loads(resp.choices[0].message.content)
    except Exception as e:
        print(f"âš ï¸ LLM JSON call failed: {e}")
        return {"error": str(e)}


def llm_text(system: str, user: str, openai_client, model: str, temperature=0.2) -> str:
    """Call OpenAI API vá»›i text response"""
    try:
        resp = openai_client.chat.completions.create(
            model=model,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
            temperature=temperature,
        )
        return resp.choices[0].message.content
    except Exception as e:
        print(f"âš ï¸ LLM text call failed: {e}")
        return f"Lá»—i: {e}"


class CriticAgent(BaseAgent):
    """
    Critic/Safety Agent - kiá»ƒm tra faithfulness vÃ  medical safety
    
    Features:
    - Faithfulness check: Answer cÃ³ trung thá»±c vá»›i sources khÃ´ng?
    - Medical safety check: KhÃ´ng Ä‘Æ°a lá»i khuyÃªn cÃ¡ nhÃ¢n, liá»u lÆ°á»£ng thuá»‘c
    - 1-pass revision náº¿u vi pháº¡m
    - Äáº£m báº£o disclaimer y táº¿ present
    """
    
    def __init__(self, openai_client, model: str, truncate_func, top_k: int = 8):
        super().__init__(name="Critic")
        self.openai_client = openai_client
        self.model = model
        self.truncate_tokens = truncate_func
        self.top_k = top_k
    
    def execute(self, state: AgentState) -> AgentState:
        """Execute critic review"""
        verbose = state.metadata.get("verbose", False)
        
        # ============================================================
        # CASE 1: Handle NLI-detected contradictions
        # Remove contradicted claims from answer
        # ============================================================
        need_removal = state.metadata.get("need_critic_removal", False)
        contradicted_claims = state.metadata.get("contradicted_claims", [])
        
        if need_removal and contradicted_claims:
            if verbose:
                print(f"ğŸ”§ Critic removing {len(contradicted_claims)} contradicted claims...")
            
            cleaned_answer = self._remove_contradicted_claims(
                state.answer, 
                contradicted_claims, 
                verbose
            )
            
            new_state = state.copy()
            new_state.answer = cleaned_answer
            new_state.metadata["critic_action"] = "REMOVED_CONTRADICTIONS"
            
            if verbose:
                print("âœ… Contradicted claims removed from answer")
            
            return new_state
        
        # ============================================================
        # CASE 2: Skip Critic if NLI already passed (APPROVED)
        # ============================================================
        nli_grounded = state.metadata.get("grounded", False)
        hallucination_check = state.metadata.get("hallucination_check", "")
        
        if nli_grounded and hallucination_check == "APPROVED":
            if verbose:
                print("â­ï¸ Critic skipped (NLI already verified: APPROVED)")
            return state
        
        # ============================================================
        # CASE 3: Full Critic check if NLI was skipped or has warnings
        # ============================================================
        chunks = state.reranked_chunks[:self.top_k]
        refs = "\n\n".join(f'[{c.get("title","Doc")} Â§{c["chunk_id"]}]\n{self.truncate_tokens(c["text"],400)}'
                          for c in chunks)
        
        if verbose:
            print("ğŸ” Critic reviewing answer...")
        
        system_prompt = (
            "Báº¡n lÃ  Critic & Safety Evaluator. Nhiá»‡m vá»¥ QUAN TRá»ŒNG: Kiá»ƒm tra nghiÃªm ngáº·t tÃ­nh trung thá»±c cá»§a cÃ¢u tráº£ lá»i.\\n\\n"
            "KIá»‚M TRA FAITHFULNESS (Äá»™ trung thá»±c):\\n"
            "- Tá»«ng cÃ¢u trong answer cÃ³ Ä‘Æ°á»£c há»— trá»£ bá»Ÿi sources khÃ´ng?\\n"
            "- CÃ³ thÃ´ng tin nÃ o Ä‘Æ°á»£c thÃªm vÃ o mÃ  khÃ´ng cÃ³ trong sources?\\n"
            "- CÃ³ suy diá»…n hoáº·c giáº£ Ä‘á»‹nh nÃ o vÆ°á»£t quÃ¡ thÃ´ng tin trong sources?\\n"
            "- TrÃ­ch dáº«n [title Â§chunk_id] cÃ³ chÃ­nh xÃ¡c khÃ´ng?\\n"
            "- CÃ³ pháº§n 'Nguá»“n tham kháº£o' vá»›i links bÃ i viáº¿t khÃ´ng?\\n\\n"
            "KIá»‚M TRA MEDICAL SAFETY:\\n"
            "- KhÃ´ng Ä‘Æ°a lá»i khuyÃªn cháº©n Ä‘oÃ¡n/Ä‘iá»u trá»‹ cÃ¡ nhÃ¢n\\n"
            "- KhÃ´ng Ä‘Æ°a liá»u lÆ°á»£ng thuá»‘c cá»¥ thá»ƒ\\n"
            "- CÃ³ disclaimer y táº¿ khÃ´ng?\\n\\n"
            "Náº¾U vi pháº¡m báº¥t ká»³ Ä‘iá»u nÃ o â†’ action='REVISE'\\n"
            "Náº¾U táº¥t cáº£ Ä‘á»u Ä‘Ãºng â†’ action='APPROVE'\\n\\n"
            "Tráº£ JSON vá»›i keys: action (APPROVE/REVISE), notes (string), suggestion (string náº¿u cáº§n sá»­a)"
        )
        
        user_prompt = f"Answer:\n{state.answer}\n\nSources:\n{refs}"
        verdict = llm_json(system_prompt, user_prompt, self.openai_client, self.model)
        
        if verdict.get("action") == "REVISE":
            if verbose:
                print("âš ï¸ Critic requests revision")
            
            # 1-pass revision
            revise_prompt = (
                f"NHIá»†M Vá»¤: Sá»­a cÃ¢u tráº£ lá»i Ä‘á»ƒ tuÃ¢n thá»§ ghi chÃº cá»§a critic, CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« nguá»“n tham chiáº¿u.\\n\\n"
                f"GHI CHÃš Tá»ª CRITIC: {verdict.get('notes', '')}\\n"
                f"Gá»¢I Ã Sá»¬A CHá»®A: {verdict.get('suggestion', '')}\\n\\n"
                f"CÃ‚U TRáº¢ Lá»œI CÅ¨ (Cáº¦N Sá»¬A):\\n{state.answer}\\n\\n"
                f"NGUá»’N THAM CHIáº¾U (CHá»ˆ ÄÆ¯á»¢C Sá»¬ Dá»¤NG THÃ”NG TIN TRONG ÄÃ‚Y):\\n"
                f"{'='*60}\\n{refs}\\n{'='*60}\\n\\n"
                f"YÃŠU Cáº¦U: Sá»­a cÃ¢u tráº£ lá»i dá»±a trÃªn ghi chÃº cá»§a critic, Ä‘áº£m báº£o:\\n"
                f"- CHá»ˆ sá»­ dá»¥ng thÃ´ng tin cÃ³ trong nguá»“n tham chiáº¿u\\n"
                f"- CÃ³ trÃ­ch dáº«n [title Â§chunk_id] cho má»i thÃ´ng tin\\n"
                f"- KhÃ´ng thÃªm kiáº¿n thá»©c bÃªn ngoÃ i\\n"
                f"- CÃ³ disclaimer y táº¿"
            )
            
            revision_system = (
                "Báº¡n lÃ  Medical RAG Answerer. NHIá»†M Vá»¤: Sá»­a cÃ¢u tráº£ lá»i theo yÃªu cáº§u cá»§a critic.\\n\\n"
                "QUY Táº®C NGHIÃŠM NGáº¶T KHI Sá»¬A:\\n"
                "- CHá»ˆ sá»­ dá»¥ng thÃ´ng tin tá»« nguá»“n tham chiáº¿u Ä‘Æ°á»£c cung cáº¥p\\n"
                "- KHÃ”NG thÃªm kiáº¿n thá»©c tá»« bÃªn ngoÃ i\\n"
                "- PHáº¢I cÃ³ trÃ­ch dáº«n [title Â§chunk_id] cho má»i thÃ´ng tin\\n"
                "- PHáº¢I cÃ³ disclaimer y táº¿\\n"
                "- KHÃ”NG cáº§n thÃªm pháº§n 'Nguá»“n tham kháº£o' - há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng thÃªm\\n"
                "- Náº¿u thiáº¿u thÃ´ng tin trong nguá»“n, nÃ³i rÃµ 'KhÃ´ng Ä‘á»§ thÃ´ng tin trong tÃ i liá»‡u'\\n"
                "- KHÃ”NG Sá»¬ Dá»¤NG emoji hoáº·c icon trong cÃ¢u tráº£ lá»i. Giá»¯ vÄƒn phong chuyÃªn nghiá»‡p.\\n\\n"
                "Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
            )
            
            revised_answer = llm_text(
                revision_system,
                revise_prompt,
                self.openai_client,
                self.model,
                temperature=0.1
            )
            
            # Re-append source references for revised answer
            source_refs = self._build_source_references(chunks)
            if source_refs:
                final_revised_answer = f"{revised_answer}\n\n{source_refs}"
            else:
                final_revised_answer = revised_answer
            
            new_state = state.copy()
            new_state.answer = final_revised_answer
            return new_state
        else:
            if verbose:
                print("âœ… Critic approves answer")
        
        return state
    
    def _build_source_references(self, chunks: List[Dict[str, Any]]) -> str:
        """XÃ¢y dá»±ng danh sÃ¡ch nguá»“n tham kháº£o vá»›i links"""
        if not chunks:
            return ""
        
        # Group chunks by source to avoid duplicate links
        sources = {}
        for c in chunks:
            title = c.get("title", "TÃ i liá»‡u")
            source = c.get("source", "")
            if source and source not in sources:
                sources[source] = title
        
        if not sources:
            return ""
        
        ref_lines = ["## ğŸ“š Nguá»“n tham kháº£o:"]
        for i, (source, title) in enumerate(sources.items(), 1):
            ref_lines.append(f"{i}. **{title}** - {source}")
        
        return "\n".join(ref_lines)
    
    def _remove_contradicted_claims(self, answer: str, claims: List[str], verbose: bool = False) -> str:
        """
        Remove contradicted claims from the answer using LLM
        
        Args:
            answer: Original answer text
            claims: List of claims that contradict the sources
            verbose: Enable verbose logging
        """
        if not claims:
            return answer
        
        # Preserve source references section
        source_section = ""
        main_answer = answer
        if "## ğŸ“š Nguá»“n tham kháº£o:" in answer:
            parts = answer.split("## ğŸ“š Nguá»“n tham kháº£o:")
            main_answer = parts[0]
            source_section = "\n\n## ğŸ“š Nguá»“n tham kháº£o:" + parts[1]
        
        claims_list = "\n".join([f"- {claim}" for claim in claims])
        
        system_prompt = """Báº¡n lÃ  trá»£ lÃ½ y táº¿. Nhiá»‡m vá»¥: Loáº¡i bá» cÃ¡c thÃ´ng tin SAI khá»i cÃ¢u tráº£ lá»i.

QUY Táº®C:
1. XÃ“A hoÃ n toÃ n cÃ¡c cÃ¢u chá»©a thÃ´ng tin sai (Ä‘Æ°á»£c liá»‡t kÃª bÃªn dÆ°á»›i)
2. GIá»® NGUYÃŠN format: markdown, bullet points, citations
3. GIá»® NGUYÃŠN cÃ¡c thÃ´ng tin Ä‘Ãºng
4. KHÃ”NG thÃªm thÃ´ng tin má»›i
5. Äáº¢M Báº¢O cÃ¢u tráº£ lá»i váº«n máº¡ch láº¡c

Tráº£ vá» cÃ¢u tráº£ lá»i Ä‘Ã£ chá»‰nh sá»­a, KHÃ”NG giáº£i thÃ­ch."""

        user_prompt = f"""CÃ‚U TRáº¢ Lá»œI Gá»C:
{main_answer}

CÃC THÃ”NG TIN SAI (Cáº¦N XÃ“A):
{claims_list}

Viáº¿t láº¡i cÃ¢u tráº£ lá»i, loáº¡i bá» cÃ¡c thÃ´ng tin sai á»Ÿ trÃªn:"""

        try:
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.0,
                max_tokens=2000
            )
            cleaned = response.choices[0].message.content.strip()
            
            # Add warning about removed content
            warning = "\n\nâš ï¸ **LÆ°u Ã½**: Má»™t sá»‘ thÃ´ng tin Ä‘Ã£ Ä‘Æ°á»£c loáº¡i bá» do khÃ´ng phÃ¹ há»£p vá»›i nguá»“n tÃ i liá»‡u."
            
            # Re-append source section
            if source_section:
                return cleaned + warning + source_section
            return cleaned + warning
            
        except Exception as e:
            if verbose:
                print(f"   âš ï¸ Failed to remove claims: {e}")
            # Fallback: add warning to original
            return answer + "\n\nâŒ **Cáº¢NH BÃO**: Má»™t sá»‘ thÃ´ng tin trong cÃ¢u tráº£ lá»i cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c."
    
    def validate_input(self, state: AgentState) -> bool:
        """Validate input state"""
        return bool(state.answer) and isinstance(state.reranked_chunks, list)

