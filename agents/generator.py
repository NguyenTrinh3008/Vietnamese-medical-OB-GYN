#!/usr/bin/env python3
"""
Generator Agent - Sinh cÃ¢u tráº£ lá»i tá»« top chunks
Migrate tá»« generator_node(), build_context(), build_source_references() trong agentic_rag.py
"""

import sys
sys.path.append('..')

from async_agents.base import BaseAgent, AgentState
from typing import List, Dict, Any, Tuple


def llm_text(system: str, user: str, openai_client, model: str, temperature=0.0) -> str:
    """Call OpenAI API vá»›i text response"""
    try:
        resp = openai_client.chat.completions.create(
            model=model,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
            temperature=temperature,
        )
        return resp.choices[0].message.content
    except Exception as e:
        print(f"âš ï¸ LLM text call failed: {e}")
        return f"Lá»—i: {e}"


def llm_text_stream(system: str, user: str, openai_client, model: str, temperature=0.0):
    """
    Call OpenAI API vá»›i STREAMING response
    
    Yields chunks of text as they arrive from the API
    For progressive reveal in UI (better UX)
    """
    try:
        stream = openai_client.chat.completions.create(
            model=model,
            messages=[{"role":"system","content":system},{"role":"user","content":user}],
            temperature=temperature,
            stream=True  # Enable streaming
        )
        
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                yield chunk.choices[0].delta.content
                
    except Exception as e:
        print(f"âš ï¸ LLM streaming failed: {e}")
        yield f"Lá»—i: {e}"


class GeneratorAgent(BaseAgent):
    """
    Generator Agent - sinh cÃ¢u tráº£ lá»i tá»« top chunks
    
    Features:
    - Build context tá»« top-K chunks
    - Strict rules: CHá»ˆ dÃ¹ng thÃ´ng tin tá»« sources
    - Auto-append citations [title Â§chunk_id]
    - Auto-append source references vá»›i links
    - Rejection handling cho cÃ¢u há»i khÃ´ng phÃ¹ há»£p
    """
    
    def __init__(self, openai_client, model: str, truncate_func, top_k: int = 20):
        super().__init__(name="Generator")
        self.openai_client = openai_client
        self.model = model
        self.truncate_tokens = truncate_func
        self.top_k = top_k
    
    def execute(self, state: AgentState) -> AgentState:
        """Execute generation"""
        chunks = state.reranked_chunks
        verbose = state.metadata.get("verbose", False)
        
        # Handle rejection case
        if not state.plan.get("need_retrieval", True):
            rejection_reason = state.plan.get("rejection_reason", "")
            if rejection_reason:
                answer = (
                    f"Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y vÃ¬: {rejection_reason}\n\n"
                    "Há»‡ thá»‘ng chá»‰ cung cáº¥p thÃ´ng tin y khoa tá»•ng quÃ¡t tá»« tÃ i liá»‡u tham kháº£o, "
                    "khÃ´ng Ä‘Æ°a ra lá»i khuyÃªn cháº©n Ä‘oÃ¡n hoáº·c Ä‘iá»u trá»‹ cÃ¡ nhÃ¢n.\n\n"
                    "Vui lÃ²ng tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa cho cÃ¡c váº¥n Ä‘á» sá»©c khá»e cá»¥ thá»ƒ.\n\n"
                    "ThÃ´ng tin chá»‰ nháº±m tham kháº£o, khÃ´ng thay tháº¿ tÆ° váº¥n y khoa cÃ¡ nhÃ¢n."
                )
                new_state = state.copy()
                new_state.answer = answer
                return new_state
        
        ctx, chosen = self._build_context(chunks, self.top_k, verbose)
        
        if verbose:
            print(f"âœï¸ Generating answer from {len(chosen)} chunks...")
        
        system_prompt = (
            "Báº¡n lÃ  Medical RAG Answerer chuyÃªn nghiá»‡p.\\n\\n"
            "QUY Táº®C:\\n"
            "- Tráº£ lá»i Dá»°A CHÃNH XÃC trÃªn thÃ´ng tin trong cÃ¡c Ä‘oáº¡n tham chiáº¿u\\n"
            "- CÃ“ THá»‚ diá»…n giáº£i láº¡i (paraphrase) Ä‘á»ƒ dá»… hiá»ƒu hÆ¡n, NHÆ¯NG PHáº¢I GIá»® NGHÄ¨A CHÃNH XÃC tá»« nguá»“n\\n"
            "- KHÃ”NG Ä‘Æ°á»£c thÃªm thÃ´ng tin tá»« kiáº¿n thá»©c riÃªng cá»§a báº¡n\\n"
            "- Khi tá»•ng há»£p nhiá»u Ä‘iá»ƒm thÃ nh danh sÃ¡ch, CHá»ˆ liá»‡t kÃª nhá»¯ng gÃ¬ CÃ“ TRONG nguá»“n\\n"
            "- Náº¾U khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan, hÃ£y nÃ³i rÃµ 'KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» váº¥n Ä‘á» nÃ y trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p'\\n"
            "- Má»—i cÃ¢u/Ä‘oáº¡n PHáº¢I cÃ³ trÃ­ch dáº«n Ä‘áº§y Ä‘á»§ dáº¡ng [TÃªn bÃ i viáº¿t - TÃªn má»¥c - Nguá»“n X]\\n"
            "- VÃ­ dá»¥: 'Acid folic giÃºp ngÄƒn ngá»«a dá»‹ táº­t á»‘ng tháº§n kinh [Acid Folic - Táº¡i sao acid folic quan trá»ng - Nguá»“n 1]'\\n"
            "- KHÃ”NG Sá»¬ Dá»¤NG emoji hoáº·c icon (ğŸ”¹âŒâœ…ğŸ“Œ...) trong cÃ¢u tráº£ lá»i. Giá»¯ vÄƒn phong chuyÃªn nghiá»‡p, há»c thuáº­t.\\n\\n"
            "Cáº¤U TRÃšC:\\n"
            "1. TÃ³m táº¯t ngáº¯n gá»n\\n"
            "2. CÃ¡c Ä‘iá»ƒm chÃ­nh vá»›i trÃ­ch dáº«n cá»¥ thá»ƒ dáº¡ng [TÃªn bÃ i - TÃªn má»¥c - Nguá»“n X]\\n"
            "3. Káº¿t luáº­n tá»« thÃ´ng tin trong nguá»“n\\n"
            "4. Disclaimer: 'ThÃ´ng tin chá»‰ nháº±m tham kháº£o, khÃ´ng thay tháº¿ tÆ° váº¥n y khoa cÃ¡ nhÃ¢n.'\\n"
            "5. KHÃ”NG cáº§n thÃªm pháº§n 'Nguá»“n tham kháº£o' - há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng thÃªm\\n\\n"
            "Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
        )
        
        user_prompt = (
            f"CÃ¢u há»i: {state.query}\\n\\n"
            f"ÄOáº N THAM CHIáº¾U (CHá»ˆ ÄÆ¯á»¢C Sá»¬ Dá»¤NG THÃ”NG TIN TRONG ÄÃ‚Y):\\n"
            f"{'='*60}\\n"
            f"{ctx}\\n"
            f"{'='*60}\\n\\n"
            "LÆ¯U Ã: Báº¡n CHá»ˆ Ä‘Æ°á»£c tráº£ lá»i dá»±a trÃªn thÃ´ng tin cÃ³ trong cÃ¡c Ä‘oáº¡n tham chiáº¿u á»Ÿ trÃªn. "
            "KhÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng kiáº¿n thá»©c bÃªn ngoÃ i. Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan, "
            "hÃ£y nÃ³i rÃµ 'KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» váº¥n Ä‘á» nÃ y trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p'.\\n\\n"
            "HÃ£y tráº£ lá»i cÃ¢u há»i:"
        )
        
        answer = llm_text(system_prompt, user_prompt, self.openai_client, self.model, temperature=0.0)
        
        # Automatically append source references
        source_refs = self._build_source_references(chosen)
        if source_refs:
            final_answer = f"{answer}\n\n{source_refs}"
        else:
            final_answer = answer
        
        # Add query rewrite transparency if applicable
        rewritten_query = state.metadata.get("rewritten_query")
        original_query = state.metadata.get("original_query", state.query)
        
        if rewritten_query and rewritten_query != original_query:
            # Query was rewritten - add transparency note
            strategy = state.metadata.get("rewrite_strategy", "unknown")
            explanation = state.metadata.get("rewrite_explanation", "")
            intent_score = state.metadata.get("intent_similarity_score", 0)
            
            transparency_note = f"""

---

ğŸ“ **LÆ°u Ã½ vá» xá»­ lÃ½ cÃ¢u há»i:**

CÃ¢u há»i gá»‘c cá»§a báº¡n khÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u phÃ¹ há»£p, vÃ¬ váº­y há»‡ thá»‘ng Ä‘Ã£ tá»± Ä‘á»™ng viáº¿t láº¡i Ä‘á»ƒ tÃ¬m kiáº¿m tá»‘t hÆ¡n:

- **CÃ¢u há»i gá»‘c:** "{original_query}"
- **CÃ¢u há»i Ä‘Ã£ tá»‘i Æ°u:** "{rewritten_query}"
- **PhÆ°Æ¡ng phÃ¡p:** {strategy}
- **Giáº£i thÃ­ch:** {explanation}
- **Intent Guardrail:** âœ… Verified (similarity: {intent_score:.2f}/1.00)

CÃ¢u tráº£ lá»i trÃªn Ä‘Æ°á»£c táº¡o dá»±a trÃªn cÃ¢u há»i Ä‘Ã£ tá»‘i Æ°u, nhÆ°ng váº«n giá»¯ Ä‘Ãºng Ã½ Ä‘á»‹nh ban Ä‘áº§u cá»§a báº¡n.
"""
            final_answer = final_answer + transparency_note
        
        new_state = state.copy()
        new_state.answer = final_answer
        return new_state
    
    def _build_context(self, chunks: List[Dict[str, Any]], k: int, verbose: bool = False) -> Tuple[str, List[Dict[str, Any]]]:
        """XÃ¢y dá»±ng context tá»« top-k chunks vá»›i numbered citations vÃ  chunk IDs"""
        chosen = chunks[:k]  # Use configurable k (default: 20 for V2)
        blocks = []
        
        # Build source mapping for numbered citations
        source_map = {}
        source_counter = 1
        for c in chosen:
            source = c.get('source', 'N/A')
            if source and source not in source_map:
                source_map[source] = source_counter
                source_counter += 1
        
        if verbose:
            print(f"\nğŸ“„ CHI TIáº¾T CÃC CHUNKS ÄÆ¯á»¢C Sá»¬ Dá»¤NG:")
            print("=" * 80)
        
        for i, c in enumerate(chosen, 1):
            # Extract section info for citation linking
            chunk_id = c.get('chunk_id', c.get('doc_id', 'N/A'))
            section_title = self._extract_section_title(c)
            article_title = c.get('title', 'Doc').split(' - ')[0]  # Get article title only
            
            if verbose:
                print(f"\nğŸ” CHUNK {i}:")
                print(f"   Article: {article_title}")
                print(f"   Section: {section_title}")
                print(f"   Chunk ID: {chunk_id}")
                print(f"   Source: {c.get('source', 'N/A')}")
                print(f"   Text length: {len(c.get('text', ''))} chars")
                print(f"   Text preview: {c.get('text', '')[:200]}...")
                print("-" * 60)
            
            # NEW: Citation format with section title for user-friendly display
            source_num = source_map.get(c.get('source', 'N/A'), i)
            tag = f'[{article_title} - {section_title} - Nguá»“n {source_num}]'
            source_info = f"URL: {c.get('source', 'N/A')}"
            blocks.append(f"{tag}\n{source_info}\n{self.truncate_tokens(c['text'], 800)}")
        
        if verbose:
            print("=" * 80)
            print(f"âœ… ÄÃ£ chá»n {len(chosen)} chunks Ä‘á»ƒ táº¡o context\n")
        
        return "\n\n---\n\n".join(blocks), chosen
    
    def _extract_section_title(self, chunk: Dict[str, Any]) -> str:
        """
        Extract section title from chunk metadata for user-friendly citation
        
        Priority:
        1. section_title from V2 metadata
        2. Parse from full title ("Article - Section")
        3. Use chunk_id section number
        """
        # V2 hierarchical chunks have section_title in metadata
        section_title = chunk.get('section_title', '')
        if section_title:
            return section_title
        
        # Parse from full title format "Article Title - Section Title"
        full_title = chunk.get('title', '')
        if ' - ' in full_title:
            parts = full_title.split(' - ')
            if len(parts) >= 2:
                return parts[-1]  # Return last part as section
        
        # Fallback: use section number from chunk_id
        chunk_id = chunk.get('chunk_id', chunk.get('doc_id', ''))
        if '::' in str(chunk_id):
            section_num = chunk_id.split('::')[-1]
            return f"Má»¥c {section_num}"
        
        return "Ná»™i dung"
    
    def _extract_section_number(self, chunk: Dict[str, Any]) -> str:
        """
        Extract section number from chunk metadata
        
        Priority:
        1. section_number from V2 metadata (e.g., "1", "3.2")
        2. Parse from chunk_id (e.g., "art0001::3.2" -> "3.2")
        """
        # V2 hierarchical chunks have section_number in metadata
        section_number = chunk.get('section_number', '')
        if section_number:
            return section_number
        
        # Fallback: extract from chunk_id
        chunk_id = chunk.get('chunk_id', chunk.get('doc_id', ''))
        if '::' in str(chunk_id):
            return chunk_id.split('::')[-1]
        
        return ""
    
    def _build_source_references(self, chunks: List[Dict[str, Any]]) -> str:
        """
        XÃ¢y dá»±ng danh sÃ¡ch nguá»“n tham kháº£o vá»›i section numbers theo cáº¥u trÃºc hierarchical
        
        Format: [X] Article Title  Section Y: Section Title
        """
        if not chunks:
            return ""
        
        # Group chunks by source, keeping track of sections with their numbers
        sources = {}  # {source: {"title": article_title, "sections": [(section_num, section_title, html_id)]}}
        for c in chunks:
            source = c.get("source", "")
            if not source:
                continue
            
            # Get article title (first part before " - ")
            full_title = c.get("title", "TÃ i liá»‡u")
            article_title = full_title.split(' - ')[0] if ' - ' in full_title else full_title
            
            # Get section info
            section_number = self._extract_section_number(c)
            section_title = self._extract_section_title(c)
            chunk_id = c.get('chunk_id', c.get('doc_id', ''))
            
            # Create HTML-safe ID for frontend deep linking
            html_id = str(chunk_id).replace('::', '_').replace('.', '_')
            
            if source not in sources:
                sources[source] = {
                    "title": article_title,
                    "sections": []
                }
            
            # Add section if not already present (check by section_number to avoid duplicates)
            section_entry = (section_number, section_title, html_id)
            existing_nums = [s[0] for s in sources[source]["sections"]]
            if section_number not in existing_nums:
                sources[source]["sections"].append(section_entry)
        
        if not sources:
            return ""
        
        # Build reference list with hierarchical section format
        ref_lines = ["\n---\n## ğŸ“š Nguá»“n tham kháº£o:\n"]
        for i, (source, info) in enumerate(sources.items(), 1):
            article_title = info["title"]
            sections = info["sections"]
            
            # Sort sections by section number
            sections.sort(key=lambda x: self._section_sort_key(x[0]))
            
            # Build section references (limit to 3)
            valid_sections = [(num, title, hid) for num, title, hid in sections if num and title][:3]
            
            if valid_sections:
                # Format: Section X: Title â€¢ Section Y: Title
                section_parts = []
                for section_num, section_title, html_id in valid_sections:
                    section_parts.append(f"Section {section_num}: {section_title}")
                
                sections_str = " â€¢ ".join(section_parts)
                # Main article reference with sections on same line
                ref_lines.append(f"**[{i}] [{article_title}]({source})**  {sections_str}")
            else:
                # No sections, just article title
                ref_lines.append(f"**[{i}] [{article_title}]({source})**")
            
            ref_lines.append("")  # Empty line between sources
        
        return "\n".join(ref_lines)
    
    def _section_sort_key(self, section_num: str) -> tuple:
        """
        Convert section number to sortable tuple
        e.g., "3.2" -> (3, 2), "1" -> (1, 0)
        """
        if not section_num:
            return (999, 999)
        try:
            parts = section_num.split('.')
            return tuple(int(p) for p in parts) + (0,) * (2 - len(parts))
        except ValueError:
            return (999, 999)
    
    def validate_input(self, state: AgentState) -> bool:
        """Validate input state"""
        return isinstance(state.reranked_chunks, list) and isinstance(state.plan, dict)
